# AutoMock ğŸ§ªâš¡

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Go Version](https://img.shields.io/badge/Go-1.22+-00ADD8?logo=go)](https://golang.org/)
[![AWS](https://img.shields.io/badge/AWS-Supported-FF9900?logo=amazon-aws)](https://aws.amazon.com/)

**AutoMock** is an AI-powered, cloud-native CLI tool that generates and deploys production-ready mock API servers from simple descriptions, API collections, or interactive builders. Spin up ephemeral, fully managed mock servers in minutes with auto-scaling, monitoring, and intelligent expectation management.

---

## ğŸŒŸ Highlights

- ğŸ¤– **AI-Generated Mocks** - Describe your API in natural language, get complete MockServer configurations
- â˜ï¸ **Cloud-Native Deployment** - One command deploys ECS Fargate + ALB + Auto-scaling
- ğŸ“¦ **Multi-Format Import** - Postman, Bruno, Insomnia collections â†’ MockServer expectations
- ğŸ¯ **Smart Scenario Detection** - Automatically handles auth variations, error states, edge cases
- ğŸ”§ **Interactive Builder** - 7-step guided builder for precise control
- âš¡ **Auto-Scaling** - 10-200 tasks based on CPU/Memory/Requests
- ğŸ’¾ **Cloud Storage** - S3-backed, versioned, team-accessible
- ğŸ­ **Advanced Features** - Progressive delays, GraphQL, response templates, rate limiting
- ğŸ§ª **Load Testing** - Built-in Locust test generation
- ğŸ” **Production-Ready** - ALB health checks, CloudWatch monitoring, IAM best practices

---

## ğŸš€ Quick Start

```bash
# Install
git clone https://github.com/hemantobora/auto-mock.git
cd auto-mock && ./build.sh

# Configure (choose one AI provider)
export ANTHROPIC_API_KEY="sk-ant-..."  # For Claude
export OPENAI_API_KEY="sk-..."         # For GPT-4

# Create your first mock
./automock init --project user-api --provider anthropic

# Deploy to AWS (optional)
./automock deploy --project user-api
```

**Your mock API is now live!** ğŸ‰

---

## ğŸ“– Documentation

| Document | Description |
|----------|-------------|
| [GETTING_STARTED.md](GETTING_STARTED.md) | Complete setup guide, tutorials, examples |
| [terraform/README.md](terraform/README.md) | Infrastructure details, cost estimates |
| `./automock help` | Comprehensive CLI reference |

---

## âœ¨ Key Features

### ğŸ¤– AI-Powered Generation

Generate complete MockServer configurations from natural language:

```bash
./automock init --project my-api --provider anthropic
```

**Prompt:** *"User management API with registration, login, profile CRUD, password reset, and admin functions"*

**AI generates:**
- âœ… All CRUD endpoints (`GET /users`, `POST /users`, `PUT /users/{id}`, etc.)
- âœ… Authentication flows (login, logout, token refresh)
- âœ… Admin-only endpoints with proper authorization
- âœ… Error responses (400, 401, 403, 404, 500)
- âœ… Realistic test data with proper types
- âœ… Request validation rules
- âœ… Multiple scenarios per endpoint

**Supported AI Providers:**
- **Anthropic** (Claude Sonnet 4.5) - Recommended
- **OpenAI** (GPT-4)
- **Template** (No AI, fallback mode)

---

### ğŸ“¦ Collection Import

Import existing API definitions from popular tools:

```bash
./automock init \
  --project api-mock \
  --collection-file api.postman_collection.json \
  --collection-type postman
```

**Supported Formats:**
- **Postman** Collection v2.1 (.json)
- **Bruno** Collection (.json)
- **Insomnia** Workspace (.json)

**Smart Features:**
- ğŸ”„ Sequential API execution with variable resolution
- ğŸ¯ Automatic scenario detection (auth variations, error states)
- ğŸ† Intelligent priority assignment (100, 200, 300...)
- ğŸ“ Pre/post-script processing
- ğŸ” Auth header injection

**Example: Multi-Scenario Detection**
```
Same endpoint GET /api/users/123:
  Priority 100: Anonymous â†’ 401 Unauthorized
  Priority 200: Authenticated â†’ 200 OK (user data)
  Priority 300: Admin â†’ 200 OK (admin view)
  Priority 400: Rate limited â†’ 429 Too Many Requests
```

---

### ğŸ”§ Interactive Builder

Precision-controlled, step-by-step expectation creation:

```bash
./automock init --project my-api
# Select: interactive
```

**7-Step Process:**
1. **Basic Info** - Description, priority, tags
2. **Request Matching** - Method, path, query params, headers
3. **Response Configuration** - Status code, headers, body templates
4. **Advanced Features** - Delays, caching, compression
5. **Connection Options** - Socket config, keep-alive
6. **Rate Limiting** - Per-IP, per-endpoint limits
7. **Review & Confirm** - Validate before saving

**Advanced Request Matching:**
- Path parameters: `/users/{id}/orders/{orderId}`
- Regex paths: `/api/.*/status`
- Query string matching: `?status=active&limit=10`
- Header validation: `Authorization: Bearer *`
- Body matching: exact, partial, regex, JSONPath

**Response Features:**
- Template variables: `$!uuid`, `$!now_epoch`, `$!request.headers['X-Request-ID'][0]`
- Progressive delays: 100ms â†’ 150ms â†’ 200ms...
- Conditional responses based on request data
- Multiple response bodies per expectation

---

### â˜ï¸ Cloud Deployment

Deploy production-ready infrastructure with one command:

```bash
./automock deploy --project my-api
```

**What Gets Deployed:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Application Load Balancer (Public)     â”‚
â”‚  http://automock-{project}-{id}.elb...  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Target Groups     â”‚
    â”‚  â€¢ API (/)         â”‚
    â”‚  â€¢ Dashboard       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ECS Fargate Cluster                     â”‚
â”‚  â€¢ MockServer (port 1080)                â”‚
â”‚  â€¢ Config Loader (sidecar)               â”‚
â”‚  â€¢ Auto-scaling: 10-200 tasks            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  S3 Bucket          â”‚
    â”‚  expectations.json  â”‚
    â”‚  (versioned)        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Infrastructure Features:**
- âš¡ **Auto-Scaling** - CPU/Memory/Request-based (10-200 tasks)
- ğŸ” **Monitoring** - CloudWatch metrics, logs, alarms
- ğŸ¥ **Health Checks** - ALB target health, /mockserver/status
- ğŸ”’ **Security** - IAM roles, security groups, private subnets
- ğŸ’° **Cost Optimization** - Optional TTL cleanup, auto-teardown

**Accessing Your Mock:**
```bash
# API endpoint
curl http://automock-my-api-123.us-east-1.elb.amazonaws.com/api/users

# Dashboard (UI for expectations)
open http://automock-my-api-123.us-east-1.elb.amazonaws.com/mockserver/dashboard
```

---

### ğŸ“Š Project Management

Manage expectations throughout their lifecycle:

```bash
# View all expectations
./automock init --project my-api
# â†’ Select: view

# Add new expectations (any generation mode)
./automock init --project my-api
# â†’ Select: add

# Edit specific expectations
./automock init --project my-api
# â†’ Select: edit â†’ Choose endpoint â†’ Modify

# Remove some expectations
./automock init --project my-api
# â†’ Select: remove â†’ Choose endpoints

# Replace all expectations
./automock init --project my-api
# â†’ Select: replace â†’ Generate new set

# Download expectations file
./automock init --project my-api
# â†’ Select: download â†’ Saves to {project}-expectations.json

# Delete project & infrastructure
./automock init --project my-api
# â†’ Select: delete â†’ Confirms & tears down everything
```

---

### ğŸ§ª Load Testing

Generate Locust load testing bundles from collections:

```bash
./automock locust \
  --collection-file api.json \
  --collection-type postman \
  --dir ./load-tests \
  --distributed

cd load-tests
./run_locust_ui.sh

# Browser opens to http://localhost:8089
# Configure: users, spawn rate, target host
# Run load tests & view real-time metrics
```

**Generated Files:**
- `locustfile.py` - Test scenarios
- `requirements.txt` - Dependencies
- `run_locust_ui.sh` - Start with web UI
- `run_locust_headless.sh` - Run without UI
- `run_locust_master.sh` - Distributed master
- `run_locust_worker.sh` - Distributed worker

---

## ğŸ“‚ Project Structure

```
auto-mock/
â”œâ”€â”€ cmd/auto-mock/           # CLI entrypoint (main.go)
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ cloud/               # Cloud provider abstraction
â”‚   â”‚   â”œâ”€â”€ aws/             # AWS implementation (S3, ECS, IAM)
â”‚   â”‚   â”œâ”€â”€ factory.go       # Provider detection & initialization
â”‚   â”‚   â””â”€â”€ manager.go       # Orchestration & workflows
â”‚   â”œâ”€â”€ mcp/                 # AI provider integration (Anthropic, OpenAI)
â”‚   â”œâ”€â”€ builders/            # Interactive expectation builders
â”‚   â”œâ”€â”€ collections/         # Collection parsers (Postman, Bruno, Insomnia)
â”‚   â”œâ”€â”€ expectations/        # Expectation CRUD operations
â”‚   â”œâ”€â”€ repl/                # Interactive CLI flows
â”‚   â”œâ”€â”€ terraform/           # Infrastructure deployment
â”‚   â””â”€â”€ models/              # Data structures
â”œâ”€â”€ terraform/               # Terraform modules
â”‚   â”œâ”€â”€ main.tf              # Root configuration
â”‚   â”œâ”€â”€ variables.tf         # Input variables
â”‚   â””â”€â”€ outputs.tf           # Output values
â”œâ”€â”€ go.mod                   # Go dependencies
â”œâ”€â”€ build.sh                 # Build script
â”œâ”€â”€ README.md                # This file
â”œâ”€â”€ GETTING_STARTED.md       # Detailed guide
â””â”€â”€ LICENSE                  # MIT License
```

---

## ğŸ¯ Use Cases

### 1. Frontend Development
Mock backend APIs before they exist:
```bash
./automock init --project frontend-mock --provider anthropic
# Describe: "REST API for blog app: posts, comments, users"
./automock deploy --project frontend-mock

# Frontend team develops against:
# http://automock-frontend-mock-123.elb.amazonaws.com
```

### 2. Integration Testing
Consistent, controlled test environments:
```bash
# CI/CD pipeline
./automock deploy --project test-api --skip-confirmation
npm run test:integration -- --api-url http://automock-test-api-123.elb.amazonaws.com
./automock destroy --project test-api --force
```

### 3. Third-Party API Simulation
Test against external APIs without rate limits or costs:
```bash
./automock init \
  --project stripe-mock \
  --collection-file stripe-api.postman_collection.json \
  --collection-type postman
```

### 4. Performance Testing
Validate system behavior under load:
```bash
./automock locust \
  --collection-file prod-api.json \
  --collection-type postman \
  --dir ./load-tests

# Run distributed load test
cd load-tests
./run_locust_master.sh &
./run_locust_worker.sh &
./run_locust_worker.sh &
```

### 5. Demo & Prototyping
Quick API mocks for presentations:
```bash
./automock init --project demo-api --provider anthropic
# Describe API in seconds
./automock deploy --project demo-api
# Share URL with stakeholders
```

---

## ğŸ’° Cost Estimates

### AWS Infrastructure (10 tasks, 24/7)

| Component | Monthly Cost |
|-----------|--------------|
| ECS Fargate (0.25 vCPU, 0.5 GB) | ~$35 |
| Application Load Balancer | ~$16 |
| NAT Gateways (2x) | ~$64 |
| Data Transfer | ~$9 |
| CloudWatch Logs | ~$0.50 |
| S3 Storage | ~$0.30 |
| **Total** | **~$125** |

### Hourly Rate
- 10 tasks: **~$0.17/hour**
- With TTL cleanup: **Pennies per test run**

### TTL-Based Costs
| Duration | Cost |
|----------|------|
| 4 hours | ~$0.68 |
| 8 hours | ~$1.37 |
| 24 hours | ~$4.11 |
| 1 week | ~$28.77 |

### AI Generation Costs
| Provider | Cost per API Generation |
|----------|-------------------------|
| Claude Sonnet 4.5 | $0.05 - $0.20 |
| GPT-4 | $0.10 - $0.30 |

**Cost Optimization Tips:**
- Use TTL cleanup to auto-destroy infrastructure
- Destroy when not in use: `./automock destroy --project name`
- Reduce task count for smaller APIs
- Use spot instances (future feature)

---

## ğŸ—ï¸ Infrastructure Details

### Auto-Scaling Policies

**Scale Up (Aggressive):**
- CPU 70-80% â†’ +50% tasks (10 â†’ 15)
- CPU 80-90% â†’ +100% tasks (10 â†’ 20)
- CPU 90%+ â†’ +200% tasks (10 â†’ 30)
- Memory thresholds follow same pattern
- Requests/min: 500-1000 â†’ +50%, 1000+ â†’ +100%

**Scale Down (Conservative):**
- CPU < 40% for 5 minutes â†’ -25% tasks
- Cooldown: 5 minutes between scale events

**Limits:**
- Minimum: 10 tasks
- Maximum: 200 tasks

### Monitoring & Alerts

**CloudWatch Metrics:**
- ECS: CPU utilization, memory utilization, task count
- ALB: Request count, response time, 4xx/5xx errors
- Custom: Expectation reloads, config changes

**Alarms:**
- Unhealthy host count > 0
- 5XX errors > 10/minute
- CPU > 70% for 10 minutes
- Memory > 80% for 10 minutes

### Security

**IAM:**
- Least privilege access
- Separate task execution and task roles
- No hardcoded credentials

**Networking:**
- Private subnets for ECS tasks
- NAT Gateways for outbound only
- Security groups restrict traffic to ALB
- ALB in public subnets

**Data:**
- S3 server-side encryption (AES-256)
- S3 versioning enabled
- CloudWatch Logs retention: 30 days

---

## ğŸ”§ Advanced Features

### Progressive Response Delays
Simulate degrading performance:
```json
{
  "progressive": {
    "base": 100,    // Start at 100ms
    "step": 50,     // Increase by 50ms per request
    "cap": 500      // Max 500ms
  }
}
```

**Result:**
- Request 1: 100ms delay
- Request 2: 150ms delay
- Request 3: 200ms delay
- ...
- Request N: 500ms delay (stays at cap)

### Response Templates
Dynamic values in responses:
```json
{
  "id": "$!uuid",
  "timestamp": "$!now_epoch",
  "requestId": "$!request.headers['x-request-id'][0]",
  "userId": "$!request.pathParameters['userId'][0]",
  "randomScore": "$!rand_int_100"
}
```

**Available Variables:**
- `$!uuid` - Random UUID
- `$!now_epoch` - Current timestamp (epoch seconds)
- `$!rand_int_100` - Random integer (0-100)
- `$!rand_bytes_64` - Random 64 bytes (base64)
- `$!request.path` - Request path
- `$!request.method` - Request method
- `$!request.headers['X-Header'][0]` - Header value
- `$!request.pathParameters['param'][0]` - Path parameter
- `$!request.queryStringParameters['query'][0]` - Query parameter

### GraphQL Support
Create expectations for GraphQL APIs:
```json
{
  "httpRequest": {
    "method": "POST",
    "path": "/graphql",
    "body": {
      "query": {"contains": "query GetUser"},
      "variables": {"userId": "123"}
    }
  },
  "httpResponse": {
    "body": {
      "data": {
        "user": {"id": "123", "name": "John"}
      }
    }
  }
}
```

### Conditional Responses
Different responses based on request data:
```json
[
  {
    "priority": 100,
    "httpRequest": {
      "headers": {"X-User-Type": ["premium"]}
    },
    "httpResponse": {
      "body": {"features": ["all"]}
    }
  },
  {
    "priority": 200,
    "httpRequest": {},
    "httpResponse": {
      "body": {"features": ["basic"]}
    }
  }
]
```

---

## ğŸ› ï¸ Development

### Build from Source
```bash
git clone https://github.com/hemantobora/auto-mock.git
cd auto-mock
go mod download
go build -o automock ./cmd/auto-mock
```

### Run Tests
```bash
go test ./...
```

### Local Development
```bash
# Build
./build.sh

# Run with verbose logging
./automock init --project test --log-level debug
```

---

## ğŸ¤ Contributing

We welcome contributions! Here's how:

1. **Fork the repository**
2. **Create a feature branch** (`git checkout -b feature/amazing-feature`)
3. **Commit your changes** (`git commit -m 'Add amazing feature'`)
4. **Push to the branch** (`git push origin feature/amazing-feature`)
5. **Open a Pull Request**

### Areas We'd Love Help With
- [ ] Azure and GCP provider support
- [ ] Swagger/OpenAPI import
- [ ] Bruno .bru file format support
- [ ] Web UI for expectation management
- [ ] Terraform modules for other clouds
- [ ] Enhanced monitoring dashboards
- [ ] Performance optimizations

---

## ğŸ“Š Roadmap

- [x] AWS support (S3, ECS, ALB)
- [x] AI-powered mock generation (Claude, GPT-4)
- [x] Collection import (Postman, Bruno, Insomnia)
- [x] Interactive builder
- [x] Auto-scaling infrastructure
- [x] CloudWatch monitoring
- [x] Locust load testing
- [ ] Azure provider support
- [ ] GCP provider support
- [ ] Swagger/OpenAPI import
- [ ] Bruno .bru file format
- [ ] Web UI for expectation management
- [ ] Prometheus metrics export
- [ ] Custom domain support (Route53)
- [ ] Multiple region deployment
- [ ] Docker Compose local deployment
- [ ] Kubernetes deployment option

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

**Attribution Required:** If you use AutoMock in your project, please include attribution to:
```
AutoMock by Hemanto Bora
https://github.com/hemantobora/auto-mock
```

---

## ğŸ™ Acknowledgments

- **MockServer** - Powerful HTTP mocking server
- **Anthropic** - Claude AI for intelligent mock generation
- **AWS** - Cloud infrastructure platform
- **Go** - Excellent tooling and performance
- **Terraform** - Infrastructure as Code

---

## ğŸ“ Support

- **Documentation**: [GETTING_STARTED.md](GETTING_STARTED.md), `./automock help`
- **GitHub Issues**: [Create an issue](https://github.com/hemantobora/auto-mock/issues)
- **Email**: hemantobora@gmail.com

---

## â­ Star History

If you find AutoMock useful, please consider starring the repository!

---

<div align="center">

**Built with â¤ï¸ by Hemanto Bora**

[GitHub](https://github.com/hemantobora/auto-mock) â€¢ [Issues](https://github.com/hemantobora/auto-mock/issues)

</div>
